{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8b12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "from  scipy import ndimage\n",
    "import matplotlib\n",
    "from scipy import stats\n",
    "import ast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9c4e428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0.1  Unnamed: 0         kepid  \\\n",
      "0                0           0   KIC 1162345   \n",
      "1                1           1    KIC 757450   \n",
      "2                2           2    KIC 892667   \n",
      "3                3           3    KIC 892772   \n",
      "4                4           4   KIC 1026957   \n",
      "...            ...         ...           ...   \n",
      "8881          8881        8885  KIC 12833566   \n",
      "8882          8882        8886  KIC 12833701   \n",
      "8883          8883        8887  KIC 12554212   \n",
      "8884          8884        8888  KIC 12554510   \n",
      "8885          8885        8889  KIC 12834874   \n",
      "\n",
      "                                                   time  \\\n",
      "0     [ 1472.11679667  1472.13722971  1472.15766256 ...   \n",
      "1     [ 1472.11677062  1472.13720366  1472.1576365  ...   \n",
      "2     [ 1472.11677383  1472.13720687  1472.15763971 ...   \n",
      "3     [ 1472.11677918  1472.13721222  1472.15764506 ...   \n",
      "4     [ 1472.11678745  1472.13722049  1472.15765333 ...   \n",
      "...                                                 ...   \n",
      "8881  [ 1472.11806503  1472.13849828  1472.15893133 ...   \n",
      "8882  [ 1472.11806026  1472.13849351  1472.15892656 ...   \n",
      "8883  [ 1472.11799389  1472.13842714  1472.1588602  ...   \n",
      "8884  [ 1472.11799841  1472.13843166  1472.15886471 ...   \n",
      "8885  [ 1472.11807813  1472.13851136  1472.1589444  ...   \n",
      "\n",
      "                                                   flux  labels  \n",
      "0     [ 290573.1875   290615.40625  290711.09375 ......       0  \n",
      "1     [ 11482.10058594  11476.09765625  11474.229492...       1  \n",
      "2     [ 76636.7421875  76644.0390625  76627.0859375 ...       0  \n",
      "3     [ 12183.046875    12195.359375    12198.278320...       0  \n",
      "4     [ 119163.3046875  119160.125      119167.23437...       0  \n",
      "...                                                 ...     ...  \n",
      "8881  [ 564531.3125  564531.5     564517.875  ...,  ...       0  \n",
      "8882  [ 8410.2421875   8407.89648438  8421.         ...       0  \n",
      "8883  [ 54430.8984375   54404.71484375  54399.808593...       1  \n",
      "8884  [ 46273.203125    46290.1875      46293.238281...       0  \n",
      "8885  [ 19512.21679688  19538.76171875  19522.939453...       1  \n",
      "\n",
      "[8886 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('final_exop_data.csv')\n",
    "# Print the entire DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91a7d4dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0        kepid  \\\n",
      "0             0           0  KIC 1162345   \n",
      "1             2           2   KIC 892667   \n",
      "2             3           3   KIC 892772   \n",
      "3             4           4  KIC 1026957   \n",
      "4             5           5  KIC 1160891   \n",
      "5             6           6  KIC 1162150   \n",
      "\n",
      "                                                time  \\\n",
      "0  [ 1472.11679667  1472.13722971  1472.15766256 ...   \n",
      "1  [ 1472.11677383  1472.13720687  1472.15763971 ...   \n",
      "2  [ 1472.11677918  1472.13721222  1472.15764506 ...   \n",
      "3  [ 1472.11678745  1472.13722049  1472.15765333 ...   \n",
      "4  [ 1472.11678409  1472.13721714  1472.15764999 ...   \n",
      "5  [ 1472.11679794  1472.13723099  1472.15766383 ...   \n",
      "\n",
      "                                                flux  labels  \n",
      "0  [ 290573.1875   290615.40625  290711.09375 ......       0  \n",
      "1  [ 76636.7421875  76644.0390625  76627.0859375 ...       0  \n",
      "2  [ 12183.046875    12195.359375    12198.278320...       0  \n",
      "3  [ 119163.3046875  119160.125      119167.23437...       0  \n",
      "4  [ 69382.171875   69406.2421875  69431.7265625 ...       0  \n",
      "5  [ 677753.4375  675417.625   674491.3125 ...,  ...       0  \n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[df['labels'] == 0]\n",
    "\n",
    "# Get the top 6 rows from the filtered DataFrame\n",
    "top_6_tuples = filtered_df.head(6)\n",
    "top_6_tuples.reset_index(drop=True, inplace=True)\n",
    "# Print the resulting DataFrame\n",
    "print(top_6_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87a7fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     x=filtered_df['flux'].iloc[i][1:-1].split(',')\n",
    "#     # Convert the list of strings to a list of integers\n",
    "#     x= [float(item) for item in x]\n",
    "#     y=ast.literal_eval(filtered_df['time'].iloc[i])\n",
    "#     plt.plot(y,x)\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ba0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df_1 = df[df['labels'] == 1]\n",
    "\n",
    "# # Get the top 6 rows from the filtered DataFrame\n",
    "# top_6_tuples_1 = filtered_df_1.head(6)\n",
    "# top_6_tuples_1.reset_index(drop=True, inplace=True)\n",
    "# # Print the resulting DataFrame\n",
    "# print(top_6_tuples_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08606710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     x=filtered_df_1['flux'].iloc[i][1:-1].split(',')\n",
    "#     # Convert the list of strings to a list of integers\n",
    "#     x= [float(item) for item in x]\n",
    "#     y=ast.literal_eval(filtered_df_1['time'].iloc[i])\n",
    "#     plt.scatter(y,x,s=0.1)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "571e62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     x=filtered_df_1['flux'].iloc[i][1:-1].split(',')\n",
    "#     x= [float(item) for item in x]\n",
    "#     flux2 = ndimage.gaussian_filter(x, sigma=1)\n",
    "    \n",
    "#     time =ast.literal_eval(filtered_df_1['time'].iloc[i])\n",
    "#     plt.figure(figsize=(15,5))\n",
    "#     plt.ylabel('Flux, e-/s')\n",
    "#     plt.xlabel('Time, hours')\n",
    "#     plt.plot(time, flux2)\n",
    "#     print(flux2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3c14e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(6):\n",
    "#    x=filtered_df_1['flux'].iloc[i][1:-1].split(',')\n",
    "#    x= [float(item) for item in x]\n",
    "#    flux2 = ndimage.gaussian_filter(x, sigma=0.1)\n",
    "#    flux2=flux2.rolling(window=window_size, min_periods=1, center=True).mean()\n",
    "#    time =ast.literal_eval(filtered_df_1['time'].iloc[i])\n",
    "#    plt.figure(figsize=(15,5))\n",
    "#    plt.ylabel('Flux, e-/s')\n",
    "#    plt.xlabel('Time, hours')\n",
    "#    plt.plot(time, flux3)\n",
    "#    print(flux3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65597f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KIC 1162345\n",
      "KIC 892667\n",
      "KIC 892772\n",
      "KIC 1026957\n",
      "KIC 1160891\n",
      "KIC 1162150\n"
     ]
    }
   ],
   "source": [
    "for kepid in top_6_tuples['kepid']:\n",
    "    print(kepid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33adb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from light_curve import binning\n",
    "#from light_curve import kepler_io\n",
    "from light_curve import util\n",
    "# from tf_util import example_util\n",
    "from third_party.kepler_spline import kepler_spline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "210166e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_light_curve(all_time, all_flux):\n",
    "  \"\"\"Removes low-frequency variability from a light curve.\n",
    "\n",
    "  Args:\n",
    "    all_time: A list of numpy arrays; the time values of the raw light curve.\n",
    "    all_flux: A list of numpy arrays corresponding to the time arrays in\n",
    "      all_time.\n",
    "\n",
    "  Returns:\n",
    "    time: 1D NumPy array; the time values of the light curve.\n",
    "    flux: 1D NumPy array; the normalized flux values of the light curve.\n",
    "  \"\"\"\n",
    "  # Split on gaps.\n",
    "  all_time, all_flux = util.split(all_time, all_flux, gap_width=0.75)\n",
    "\n",
    "  # Fit a piecewise-cubic spline with default arguments.\n",
    "  spline = kepler_spline.fit_kepler_spline(all_time, all_flux, verbose=False)[0]\n",
    "\n",
    "  # Concatenate the piecewise light curve and spline.\n",
    "  time = np.concatenate(all_time)\n",
    "  flux = np.concatenate(all_flux)\n",
    "  spline = np.concatenate(spline)\n",
    "\n",
    "  # In rare cases the piecewise spline contains NaNs in places the spline could\n",
    "  # not be fit. We can't normalize those points if the spline isn't defined\n",
    "  # there. Instead we just remove them.\n",
    "  finite_i = np.isfinite(spline)\n",
    "  if not np.all(finite_i):\n",
    "    time = time[finite_i]\n",
    "    flux = flux[finite_i]\n",
    "    spline = spline[finite_i]\n",
    "\n",
    "  # \"Flatten\" the light curve (remove low-frequency variability) by dividing by\n",
    "  # the spline.\n",
    "  flux /= spline\n",
    "\n",
    "  return time, flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdbcb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_kepler_spline(all_time,\n",
    "                      all_flux,\n",
    "                      bkspace_min=0.5,\n",
    "                      bkspace_max=20,\n",
    "                      bkspace_num=20,\n",
    "                      maxiter=5,\n",
    "                      penalty_coeff=1.0,\n",
    "                      verbose=True):\n",
    "  \"\"\"Fits a Kepler spline with logarithmically-sampled breakpoint spacings.\n",
    "\n",
    "  Args:\n",
    "    all_time: List of 1D numpy arrays; the time values of the light curve.\n",
    "    all_flux: List of 1D numpy arrays; the flux values of the light curve.\n",
    "    bkspace_min: Minimum breakpoint spacing to try.\n",
    "    bkspace_max: Maximum breakpoint spacing to try.\n",
    "    bkspace_num: Number of breakpoint spacings to try.\n",
    "    maxiter: Maximum number of attempts to fit each spline after removing badly\n",
    "      fit points.\n",
    "    penalty_coeff: Coefficient of the penalty term for using more parameters in\n",
    "      the Bayesian Information Criterion. Decreasing this value will allow more\n",
    "      parameters to be used (i.e. smaller break-point spacing), and vice-versa.\n",
    "    verbose: Whether to log individual spline errors. Note that if bkspaces\n",
    "      contains many values (particularly small ones) then this may cause logging\n",
    "      pollution if calling this function for many light curves.\n",
    "\n",
    "  Returns:\n",
    "    spline: List of numpy arrays; values of the best-fit spline corresponding to\n",
    "        to the input flux arrays.\n",
    "    metadata: Object containing metadata about the spline fit.\n",
    "  \"\"\"\n",
    "  # Logarithmically sample bkspace_num candidate break point spacings between\n",
    "  # bkspace_min and bkspace_max.\n",
    "  bkspaces = np.logspace(\n",
    "      np.log10(bkspace_min), np.log10(bkspace_max), num=bkspace_num)\n",
    "\n",
    "  return choose_kepler_spline(\n",
    "      all_time,\n",
    "      all_flux,\n",
    "      bkspaces,\n",
    "      maxiter=maxiter,\n",
    "      penalty_coeff=penalty_coeff,\n",
    "      verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d46e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_kepler_spline(all_time,\n",
    "                         all_flux,\n",
    "                         bkspaces,\n",
    "                         maxiter=5,\n",
    "                         penalty_coeff=1.0,\n",
    "                         verbose=True):\n",
    "  \"\"\"Computes the best-fit Kepler spline across a break-point spacings.\n",
    "\n",
    "  Some Kepler light curves have low-frequency variability, while others have\n",
    "  very high-frequency variability (e.g. due to rapid rotation). Therefore, it is\n",
    "  suboptimal to use the same break-point spacing for every star. This function\n",
    "  computes the best-fit spline by fitting splines with different break-point\n",
    "  spacings, calculating the Bayesian Information Criterion (BIC) for each\n",
    "  spline, and choosing the break-point spacing that minimizes the BIC.\n",
    "\n",
    "  This function assumes a piecewise light curve, that is, a light curve that is\n",
    "  divided into different segments (e.g. split by quarter breaks or gaps in the\n",
    "  in the data). A separate spline is fit for each segment.\n",
    "\n",
    "  Args:\n",
    "    all_time: List of 1D numpy arrays; the time values of the light curve.\n",
    "    all_flux: List of 1D numpy arrays; the flux values of the light curve.\n",
    "    bkspaces: List of break-point spacings to try.\n",
    "    maxiter: Maximum number of attempts to fit each spline after removing badly\n",
    "      fit points.\n",
    "    penalty_coeff: Coefficient of the penalty term for using more parameters in\n",
    "      the Bayesian Information Criterion. Decreasing this value will allow more\n",
    "      parameters to be used (i.e. smaller break-point spacing), and vice-versa.\n",
    "    verbose: Whether to log individual spline errors. Note that if bkspaces\n",
    "      contains many values (particularly small ones) then this may cause logging\n",
    "      pollution if calling this function for many light curves.\n",
    "\n",
    "  Returns:\n",
    "    spline: List of numpy arrays; values of the best-fit spline corresponding to\n",
    "        to the input flux arrays.\n",
    "    metadata: Object containing metadata about the spline fit.\n",
    "  \"\"\"\n",
    "  # Initialize outputs.\n",
    "  best_spline = None\n",
    "  metadata = SplineMetadata()\n",
    "\n",
    "  # Compute the assumed standard deviation of Gaussian white noise about the\n",
    "  # spline model. We assume that each flux value f[i] is a Gaussian random\n",
    "  # variable f[i] ~ N(s[i], sigma^2), where s is the value of the true spline\n",
    "  # model and sigma is the constant standard deviation for all flux values.\n",
    "  # Moreover, we assume that s[i] ~= s[i+1]. Therefore,\n",
    "  # (f[i+1] - f[i]) / sqrt(2) ~ N(0, sigma^2).\n",
    "  scaled_diffs = [np.diff(f) / np.sqrt(2) for f in all_flux]\n",
    "  scaled_diffs = np.concatenate(scaled_diffs) if scaled_diffs else np.array([])\n",
    "  if not scaled_diffs.size:\n",
    "    best_spline = [np.array([np.nan] * len(f)) for f in all_flux]\n",
    "    metadata.light_curve_mask = [\n",
    "        np.zeros_like(f, dtype=bool) for f in all_flux\n",
    "    ]\n",
    "    return best_spline, metadata\n",
    "\n",
    "  # Compute the median absolute deviation as a robust estimate of sigma. The\n",
    "  # conversion factor of 1.48 takes the median absolute deviation to the\n",
    "  # standard deviation of a normal distribution. See, e.g.\n",
    "  # https://www.mathworks.com/help/stats/mad.html.\n",
    "  sigma = np.median(np.abs(scaled_diffs)) * 1.48\n",
    "\n",
    "  for bkspace in bkspaces:\n",
    "    nparams = 0  # Total number of free parameters in the piecewise spline.\n",
    "    npoints = 0  # Total number of data points used to fit the piecewise spline.\n",
    "    ssr = 0  # Sum of squared residuals between the model and the spline.\n",
    "\n",
    "    spline = []\n",
    "    light_curve_mask = []\n",
    "    bad_bkspace = False  # Indicates that the current bkspace should be skipped.\n",
    "    for time, flux in zip(all_time, all_flux):\n",
    "      # Fit B-spline to this light-curve segment.\n",
    "      try:\n",
    "        spline_piece, mask = kepler_spline(\n",
    "            time, flux, bkspace=bkspace, maxiter=maxiter)\n",
    "      except InsufficientPointsError as e:\n",
    "        # It's expected to occasionally see intervals with insufficient points,\n",
    "        # especially if periodic signals have been removed from the light curve.\n",
    "        # Skip this interval, but continue fitting the spline.\n",
    "        if verbose:\n",
    "          warnings.warn(str(e))\n",
    "        spline.append(np.array([np.nan] * len(flux)))\n",
    "        light_curve_mask.append(np.zeros_like(flux, dtype=bool))\n",
    "        continue\n",
    "      except SplineError as e:\n",
    "        # It's expected to get a SplineError occasionally for small values of\n",
    "        # bkspace. Skip this bkspace.\n",
    "        if verbose:\n",
    "          warnings.warn(\"Bad bkspace {}: {}\".format(bkspace, e))\n",
    "        metadata.bad_bkspaces.append(bkspace)\n",
    "        bad_bkspace = True\n",
    "        break\n",
    "\n",
    "      spline.append(spline_piece)\n",
    "      light_curve_mask.append(mask)\n",
    "\n",
    "      # Accumulate the number of free parameters.\n",
    "      total_time = np.max(time) - np.min(time)\n",
    "      nknots = int(total_time / bkspace) + 1  # From the bspline implementation.\n",
    "      nparams += nknots + 3 - 1  # number of knots + degree of spline - 1\n",
    "\n",
    "      # Accumulate the number of points and the squared residuals.\n",
    "      npoints += np.sum(mask)\n",
    "      ssr += np.sum((flux[mask] - spline_piece[mask])**2)\n",
    "\n",
    "    if bad_bkspace or not npoints:\n",
    "      continue\n",
    "\n",
    "    # The following term is -2*ln(L), where L is the likelihood of the data\n",
    "    # given the model, under the assumption that the model errors are iid\n",
    "    # Gaussian with mean 0 and standard deviation sigma.\n",
    "    likelihood_term = npoints * np.log(2 * np.pi * sigma**2) + ssr / sigma**2\n",
    "\n",
    "    # Penalty term for the number of parameters used to fit the model.\n",
    "    penalty_term = nparams * np.log(npoints)\n",
    "\n",
    "    # Bayesian information criterion.\n",
    "    bic = likelihood_term + penalty_coeff * penalty_term\n",
    "\n",
    "    if best_spline is None or bic < metadata.bic:\n",
    "      best_spline = spline\n",
    "      metadata.light_curve_mask = light_curve_mask\n",
    "      metadata.bkspace = bkspace\n",
    "      metadata.likelihood_term = likelihood_term\n",
    "      metadata.penalty_term = penalty_term\n",
    "      metadata.bic = bic\n",
    "\n",
    "  if best_spline is None:\n",
    "    # All bkspaces resulted in a SplineError, or all light curve intervals had\n",
    "    # insufficient points.\n",
    "    best_spline = [np.array([np.nan] * len(f)) for f in all_flux]\n",
    "    metadata.light_curve_mask = [\n",
    "        np.zeros_like(f, dtype=bool) for f in all_flux\n",
    "    ]\n",
    "\n",
    "  return best_spline, metadata\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
